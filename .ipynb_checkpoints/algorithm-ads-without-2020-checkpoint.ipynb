{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from collections import Counter\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With resampling, TSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/us-accidents/US_accidents_processed.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4f79ece3caba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0musAccidents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/us-accidents/US_accidents_processed.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Severity'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Heavy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0musAccidents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Start_Time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musAccidents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Start_Time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/Miguel Baptista/Documents/MEIC/2Ano_1Semestre_erasmus/TDT4173-MachineLearning/group-assignment/Machine-Learning-21-22/venv/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/Miguel Baptista/Documents/MEIC/2Ano_1Semestre_erasmus/TDT4173-MachineLearning/group-assignment/Machine-Learning-21-22/venv/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/Miguel Baptista/Documents/MEIC/2Ano_1Semestre_erasmus/TDT4173-MachineLearning/group-assignment/Machine-Learning-21-22/venv/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/Miguel Baptista/Documents/MEIC/2Ano_1Semestre_erasmus/TDT4173-MachineLearning/group-assignment/Machine-Learning-21-22/venv/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/Miguel Baptista/Documents/MEIC/2Ano_1Semestre_erasmus/TDT4173-MachineLearning/group-assignment/Machine-Learning-21-22/venv/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/Miguel Baptista/Documents/MEIC/2Ano_1Semestre_erasmus/TDT4173-MachineLearning/group-assignment/Machine-Learning-21-22/venv/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/Miguel Baptista/Documents/MEIC/2Ano_1Semestre_erasmus/TDT4173-MachineLearning/group-assignment/Machine-Learning-21-22/venv/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/us-accidents/US_accidents_processed.csv'"
     ]
    }
   ],
   "source": [
    "usAccidents = pd.read_csv(\"US_accidents_processed.csv\", dtype = {'Severity' : object}) #Heavy\n",
    "usAccidents['Start_Time'] = pd.to_datetime(usAccidents['Start_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usAccidents = usAccidents.sort_values(by=['Start_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(usAccidents.Severity.value_counts())\n",
    "usAccidents = usAccidents.drop(usAccidents[usAccidents.Year == 2020].index)\n",
    "usAccidents\n",
    "print(usAccidents.Severity.value_counts())\n",
    "\n",
    "#Now no severity 1\n",
    "#Proportion changes, before 85% were severity 2, now 78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in usAccidents.columns:\n",
    "    col_type = usAccidents[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        usAccidents[c] = usAccidents[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersample\n",
    "counter = Counter(usAccidents['Severity'])\n",
    "print(counter)\n",
    "\n",
    "under = RandomUnderSampler()\n",
    "\n",
    "X_res, y_res = under.fit_resample(usAccidents.drop(['Severity'], axis=1), usAccidents['Severity'])\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "\n",
    "#Put together to order by time\n",
    "X_res['Severity'] = y_res\n",
    "X_res = X_res.sort_values(by=['Start_Time'])\n",
    "y_res = X_res['Severity']\n",
    "X_res = X_res.drop(['Start_Time','Severity'], axis=1)\n",
    "\n",
    "#It's a time series, need to split wrt time\n",
    "#Take 80% for train and 20% for test\n",
    "X_train = X_res.iloc[0:int(X_res.shape[0]*0.8)]\n",
    "y_train = y_res.iloc[0:int(y_res.shape[0]*0.8)]\n",
    "\n",
    "X_test = (X_res.merge(X_train, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']).drop(['_merge'],axis=1)\n",
    "y_test = y_res.iloc[int(y_res.shape[0]*0.8):y_res.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best param .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    learning_rate=0.037485092594051916, \n",
    "    max_depth=7, \n",
    "    n_estimators=396, \n",
    "    num_leaves=32, \n",
    "    subsample_for_bin=202824,\n",
    "    \n",
    "    metric='multi_logloss',\n",
    "    num_class = 3, #No severity 1\n",
    "    objective = \"multiclass\"\n",
    "    )\n",
    "# [('boosting_type', 'gbdt'),\n",
    "#              ('learning_rate', 0.037485092594051916),\n",
    "#              ('max_depth', 7),\n",
    "#              ('n_estimators', 396),\n",
    "#              ('num_leaves', 32),\n",
    "#              ('subsample_for_bin', 202824)])\n",
    "# LightGBM Model accuracy score: 0.8333\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            2       0.93      0.92      0.92      7995\n",
    "#            3       0.67      0.71      0.69      2991\n",
    "#            4       0.76      0.75      0.76      3583\n",
    "\n",
    "#     accuracy                           0.83     14569\n",
    "#    macro avg       0.79      0.79      0.79     14569\n",
    "# weighted avg       0.84      0.83      0.83     14569\n",
    "# Again better with 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_prediction = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(lgbm_prediction, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, lgbm_prediction)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, lgbm_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = lgbm.feature_importances_\n",
    "lgbm_importances = pd.Series(importances, index=usAccidents.drop(['Severity','Start_Time'], axis=1).columns)\n",
    "print(importances)\n",
    "fig, ax = plt.subplots()\n",
    "lgbm_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Gini Importance\")\n",
    "ax.set_ylabel(\"Importance\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without resampling, TSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usAccidents = pd.read_csv(\"../input/us-accidents/US_accidents_processed.csv\", dtype = {'Severity' : object}) #Heavy\n",
    "usAccidents['Start_Time'] = pd.to_datetime(usAccidents['Start_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usAccidents = usAccidents.sort_values(by=['Start_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(usAccidents.Severity.value_counts())\n",
    "usAccidents = usAccidents.drop(usAccidents[usAccidents.Year == 2020].index)\n",
    "usAccidents\n",
    "print(usAccidents.Severity.value_counts())\n",
    "\n",
    "#Now no severity 1\n",
    "#Proportion changes, before 85% were severity 2, now 78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in usAccidents.columns:\n",
    "    col_type = usAccidents[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        usAccidents[c] = usAccidents[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It's a time series, need to split wrt time\n",
    "#Take 80% for train and 20% for test\n",
    "#TRAIN TEST NO RESAMPLING TIME SERIES\n",
    "X_res = usAccidents.drop(['Severity','Start_Time'], axis=1)\n",
    "y_res = usAccidents['Severity']\n",
    "X_train = X_res.iloc[0:int(X_res.shape[0]*0.8)]\n",
    "y_train = y_res.iloc[0:int(y_res.shape[0]*0.8)]\n",
    "\n",
    "X_test = (X_res.merge(X_train, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']).drop(['_merge'],axis=1)\n",
    "y_test = y_res.iloc[int(y_res.shape[0]*0.8):y_res.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best params.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(\n",
    "    boosting_type='dart',\n",
    "    learning_rate=0.29215143108583874, \n",
    "    max_depth=3, \n",
    "    n_estimators=789, \n",
    "    num_leaves=52, \n",
    "    subsample_for_bin=201458,\n",
    "    \n",
    "    metric='multi_logloss',\n",
    "    num_class = 3,\n",
    "    objective = \"multiclass\"\n",
    "    )\n",
    "# [('boosting_type', 'dart'),\n",
    "#              ('learning_rate', 0.29215143108583874),\n",
    "#              ('max_depth', 3),\n",
    "#              ('n_estimators', 789),\n",
    "#              ('num_leaves', 52),\n",
    "#              ('subsample_for_bin', 201458)]\n",
    "# LightGBM Model accuracy score: 0.9347\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            2       0.95      0.99      0.97     45471\n",
    "#            3       0.70      0.49      0.57      2701\n",
    "#            4       0.73      0.47      0.57      2579\n",
    "\n",
    "#     accuracy                           0.93     50751\n",
    "#    macro avg       0.79      0.65      0.71     50751\n",
    "# weighted avg       0.93      0.93      0.93     50751\n",
    "# Again better with 2 but better than with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_prediction = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(lgbm_prediction, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, lgbm_prediction)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, lgbm_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = lgbm.feature_importances_\n",
    "lgbm_importances = pd.Series(importances, index=usAccidents.drop(['Severity','Start_Time'], axis=1).columns)\n",
    "print(importances)\n",
    "fig, ax = plt.subplots()\n",
    "lgbm_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Gini Importance\")\n",
    "ax.set_ylabel(\"Importance\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIth KFold, whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usAccidents = pd.read_csv(\"../input/us-accidents/US_accidents_processed.csv\", dtype = {'Severity' : object}) #Heavy\n",
    "usAccidents['Start_Time'] = pd.to_datetime(usAccidents['Start_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usAccidents = usAccidents.sort_values(by=['Start_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(usAccidents.Severity.value_counts())\n",
    "usAccidents = usAccidents.drop(usAccidents[usAccidents.Year == 2020].index)\n",
    "usAccidents\n",
    "print(usAccidents.Severity.value_counts())\n",
    "\n",
    "#Now no severity 1\n",
    "#Proportion changes, before 85% were severity 2, now 78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in usAccidents.columns:\n",
    "    col_type = usAccidents[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        usAccidents[c] = usAccidents[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take 80% for train and 20% for test\n",
    "#TRAIN TEST NO RESAMPLING\n",
    "usAccidents =usAccidents.sample(frac=1) #KFOLD\n",
    "X_res = usAccidents.drop(['Severity','Start_Time'], axis=1)\n",
    "y_res = usAccidents['Severity']\n",
    "\n",
    "#KFold\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res, test_size=0.20, \n",
    "    random_state=314, stratify= y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best param.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    learning_rate=0.22222317015932044, \n",
    "    max_depth=9, \n",
    "    n_estimators=766, \n",
    "    num_leaves=58, \n",
    "    subsample_for_bin=200828,\n",
    "    \n",
    "    metric='multi_logloss',\n",
    "    num_class = 3,\n",
    "    objective = \"multiclass\"\n",
    "    )\n",
    "# [('boosting_type', 'gbdt'),\n",
    "#              ('learning_rate', 0.22222317015932044),\n",
    "#              ('max_depth', 9),\n",
    "#              ('n_estimators', 766),\n",
    "#              ('num_leaves', 58),\n",
    "#              ('subsample_for_bin', 200828)]\n",
    "# LightGBM Model accuracy score: 0.8611\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            2       0.90      0.95      0.92     39620\n",
    "#            3       0.63      0.47      0.54      6275\n",
    "#            4       0.74      0.65      0.69      4856\n",
    "\n",
    "#     accuracy                           0.86     50751\n",
    "#    macro avg       0.75      0.69      0.72     50751\n",
    "# weighted avg       0.85      0.86      0.85     50751\n",
    "# Again better with sev 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_prediction = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(lgbm_prediction, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, lgbm_prediction)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, lgbm_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = lgbm.feature_importances_\n",
    "lgbm_importances = pd.Series(importances, index=usAccidents.drop(['Severity','Start_Time'], axis=1).columns)\n",
    "print(importances)\n",
    "fig, ax = plt.subplots()\n",
    "lgbm_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Gini Importance\")\n",
    "ax.set_ylabel(\"Importance\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With KFold, resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usAccidents = pd.read_csv(\"../input/us-accidents/US_accidents_processed.csv\", dtype = {'Severity' : object}) #Heavy\n",
    "usAccidents['Start_Time'] = pd.to_datetime(usAccidents['Start_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usAccidents = usAccidents.sort_values(by=['Start_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(usAccidents.Severity.value_counts())\n",
    "usAccidents = usAccidents.drop(usAccidents[usAccidents.Year == 2020].index)\n",
    "usAccidents\n",
    "print(usAccidents.Severity.value_counts())\n",
    "\n",
    "#Now no severity 1\n",
    "#Proportion changes, before 85% were severity 2, now 78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in usAccidents.columns:\n",
    "    col_type = usAccidents[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        usAccidents[c] = usAccidents[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersample\n",
    "counter = Counter(usAccidents['Severity'])\n",
    "print(counter)\n",
    "\n",
    "under = RandomUnderSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usAccidents =usAccidents.sample(frac=1) #KFOLD\n",
    "X_res, y_res = under.fit_resample(usAccidents.drop(['Severity','Start_Time'], axis=1), usAccidents['Severity'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res, test_size=0.20, \n",
    "    random_state=314, stratify= y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best param.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skopt import BayesSearchCV\n",
    "# from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# lgbm_clf = LGBMClassifier(\n",
    "#     metric='multi_logloss',\n",
    "#     num_class = 3,\n",
    "#     objective = \"multiclass\"\n",
    "#     )\n",
    "\n",
    "# search_space = {\n",
    "#     \"boosting_type\": Categorical(['gbdt', 'dart','goss']),\n",
    "#         \"num_leaves\": Integer(6, 60), \n",
    "#         \"max_depth\": Integer(-1, 10), \n",
    "#         \"learning_rate\": Real(0.001,1),\n",
    "#         \"n_estimators\": Integer(2, 1000),\n",
    "#         \"subsample_for_bin\": Integer(199000, 204000),\n",
    "#     }\n",
    "\n",
    "# cv = KFold(n_splits=5,shuffle=True)\n",
    "\n",
    "# def on_step(val):\n",
    "#     print(\"DONE\")\n",
    "\n",
    "\n",
    "# lgbm_bayes_search = BayesSearchCV(\n",
    "#     estimator = lgbm_clf, \n",
    "#     search_spaces = search_space, \n",
    "#     n_iter=10, # specify how many iterations    \n",
    "#     scoring=\"accuracy\",\n",
    "#     cv=cv,\n",
    "#     verbose =0,\n",
    "#     n_jobs= -1\n",
    "# )\n",
    "# lgbm_bayes_search.fit(X_train, y_train, callback = on_step) # callback=on_step will print after each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_bayes_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_bayes_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    learning_rate=0.39326998667103985, \n",
    "    max_depth=6, \n",
    "    n_estimators=657, \n",
    "    num_leaves=30, \n",
    "    subsample_for_bin=199317,\n",
    "    \n",
    "    metric='multi_logloss',\n",
    "    num_class = 3,\n",
    "    objective = \"multiclass\"\n",
    "    )\n",
    "# [('boosting_type', 'gbdt'),\n",
    "#              ('learning_rate', 0.39326998667103985),\n",
    "#              ('max_depth', 6),\n",
    "#              ('n_estimators', 657),\n",
    "#              ('num_leaves', 30),\n",
    "#              ('subsample_for_bin', 199317)]\n",
    "# LightGBM Model accuracy score: 0.7481\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            2       0.81      0.74      0.77      4857\n",
    "#            3       0.68      0.70      0.69      4856\n",
    "#            4       0.76      0.81      0.78      4856\n",
    "\n",
    "#     accuracy                           0.75     14569\n",
    "#    macro avg       0.75      0.75      0.75     14569\n",
    "# weighted avg       0.75      0.75      0.75     14569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_prediction = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(lgbm_prediction, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, lgbm_prediction)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, lgbm_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importances = lgbm.feature_importances_\n",
    "lgbm_importances = pd.Series(importances, index=usAccidents.drop(['Severity','Start_Time'], axis=1).columns)\n",
    "print(importances)\n",
    "fig, ax = plt.subplots()\n",
    "lgbm_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Gini Importance\")\n",
    "ax.set_ylabel(\"Importance\")\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
